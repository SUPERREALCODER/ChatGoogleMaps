{"version":3,"sources":["../../src/hooks/use-chat.ts","../../src/utils/fetch-chat-completion.ts"],"sourcesContent":["import { useRef, useState } from \"react\";\nimport {\n  Message,\n  ToolDefinition,\n  FunctionCallHandler,\n  encodeResult,\n  FunctionCall,\n  COPILOT_CLOUD_PUBLIC_API_KEY_HEADER,\n} from \"@copilotkit/shared\";\n\nimport { nanoid } from \"nanoid\";\nimport { fetchAndDecodeChatCompletion } from \"../utils/fetch-chat-completion\";\nimport { CopilotApiConfig } from \"../context\";\nimport untruncateJson from \"untruncate-json\";\n\nexport type UseChatOptions = {\n  /**\n   * The API endpoint that accepts a `{ messages: Message[] }` object and returns\n   * a stream of tokens of the AI chat response. Defaults to `/api/chat`.\n   */\n  api?: string;\n  /**\n   * A unique identifier for the chat. If not provided, a random one will be\n   * generated. When provided, the `useChat` hook with the same `id` will\n   * have shared states across components.\n   */\n  id?: string;\n  /**\n   * System messages of the chat. Defaults to an empty array.\n   */\n  initialMessages?: Message[];\n  /**\n   * Callback function to be called when a function call is received.\n   * If the function returns a `ChatRequest` object, the request will be sent\n   * automatically to the API and will be used to update the chat.\n   */\n  onFunctionCall?: FunctionCallHandler;\n  /**\n   * HTTP headers to be sent with the API request.\n   */\n  headers?: Record<string, string> | Headers;\n  /**\n   * Extra body object to be sent with the API request.\n   * @example\n   * Send a `sessionId` to the API along with the messages.\n   * ```js\n   * useChat({\n   *   body: {\n   *     sessionId: '123',\n   *   }\n   * })\n   * ```\n   */\n  body?: object;\n  /**\n   * Function definitions to be sent to the API.\n   */\n  tools?: ToolDefinition[];\n};\n\nexport type UseChatHelpers = {\n  /**\n   * Append a user message to the chat list. This triggers the API call to fetch\n   * the assistant's response.\n   * @param message The message to append\n   */\n  append: (message: Message) => Promise<void>;\n  /**\n   * Reload the last AI chat response for the given chat history. If the last\n   * message isn't from the assistant, it will request the API to generate a\n   * new response.\n   */\n  reload: () => Promise<void>;\n  /**\n   * Abort the current request immediately, keep the generated tokens if any.\n   */\n  stop: () => void;\n  /** The current value of the input */\n  input: string;\n  /** setState-powered method to update the input value */\n  setInput: React.Dispatch<React.SetStateAction<string>>;\n  /** Whether the API request is in progress */\n  isLoading: boolean;\n};\n\nexport type UseChatOptionsWithCopilotConfig = UseChatOptions & {\n  copilotConfig: CopilotApiConfig;\n  /**\n   * The current list of messages in the chat.\n   */\n  messages: Message[];\n  /**\n   * The setState-powered method to update the chat messages.\n   */\n  setMessages: React.Dispatch<React.SetStateAction<Message[]>>;\n};\n\nexport function useChat(options: UseChatOptionsWithCopilotConfig): UseChatHelpers {\n  const { messages, setMessages } = options;\n  const [input, setInput] = useState(\"\");\n  const [isLoading, setIsLoading] = useState(false);\n  const abortControllerRef = useRef<AbortController>();\n  const threadIdRef = useRef<string | null>(null);\n  const runIdRef = useRef<string | null>(null);\n  const publicApiKey = options.copilotConfig.publicApiKey;\n  const headers = {\n    ...(options.headers || {}),\n    ...(publicApiKey ? { [COPILOT_CLOUD_PUBLIC_API_KEY_HEADER]: publicApiKey } : {}),\n  };\n\n  const runChatCompletion = async (messages: Message[]): Promise<Message[]> => {\n    setIsLoading(true);\n\n    const newMessages: Message[] = [\n      {\n        id: nanoid(),\n        createdAt: new Date(),\n        content: \"\",\n        role: \"assistant\",\n      },\n    ];\n    const abortController = new AbortController();\n    abortControllerRef.current = abortController;\n\n    setMessages([...messages, ...newMessages]);\n\n    // add threadId and runId to the body if it exists\n    const copilotConfigBody = options.copilotConfig.body || {};\n    if (threadIdRef.current) {\n      copilotConfigBody.threadId = threadIdRef.current;\n    }\n    if (runIdRef.current) {\n      copilotConfigBody.runId = runIdRef.current;\n    }\n\n    const messagesWithContext = [...(options.initialMessages || []), ...messages];\n    const response = await fetchAndDecodeChatCompletion({\n      copilotConfig: { ...options.copilotConfig, body: copilotConfigBody },\n      messages: messagesWithContext,\n      tools: options.tools,\n      headers: headers,\n      signal: abortController.signal,\n    });\n\n    if (response.headers.get(\"threadid\")) {\n      threadIdRef.current = response.headers.get(\"threadid\");\n    }\n\n    if (response.headers.get(\"runid\")) {\n      runIdRef.current = response.headers.get(\"runid\");\n    }\n\n    if (!response.events) {\n      setMessages([\n        ...messages,\n        {\n          id: nanoid(),\n          createdAt: new Date(),\n          content: response.statusText,\n          role: \"assistant\",\n        },\n      ]);\n      setIsLoading(false);\n      throw new Error(\"Failed to fetch chat completion\");\n    }\n\n    const reader = response.events.getReader();\n\n    // Whether to feed back the new messages to GPT\n    let feedback = false;\n\n    try {\n      while (true) {\n        const { done, value } = await reader.read();\n\n        if (done) {\n          break;\n        }\n\n        let currentMessage = Object.assign({}, newMessages[newMessages.length - 1]);\n\n        if (value.type === \"content\") {\n          if (currentMessage.function_call || currentMessage.role === \"function\") {\n            // Create a new message if the previous one is a function call or result\n            currentMessage = {\n              id: nanoid(),\n              createdAt: new Date(),\n              content: \"\",\n              role: \"assistant\",\n            };\n            newMessages.push(currentMessage);\n          }\n          currentMessage.content += value.content;\n          newMessages[newMessages.length - 1] = currentMessage;\n          setMessages([...messages, ...newMessages]);\n        } else if (value.type === \"result\") {\n          // When we get a result message, it is already complete\n          currentMessage = {\n            id: nanoid(),\n            role: \"function\",\n            content: value.content,\n            name: value.name,\n          };\n          newMessages.push(currentMessage);\n          setMessages([...messages, ...newMessages]);\n\n          // After receiving a result, feed back the new messages to GPT\n          feedback = true;\n        } else if (value.type === \"function\" || value.type === \"partial\") {\n          // Create a new message if the previous one is not empty\n          if (\n            currentMessage.content != \"\" ||\n            currentMessage.function_call ||\n            currentMessage.role == \"function\"\n          ) {\n            currentMessage = {\n              id: nanoid(),\n              createdAt: new Date(),\n              content: \"\",\n              role: \"assistant\",\n            };\n            newMessages.push(currentMessage);\n          }\n          if (value.type === \"function\") {\n            currentMessage.function_call = {\n              name: value.name,\n              arguments: JSON.stringify(value.arguments),\n              scope: value.scope,\n            };\n          } else if (value.type === \"partial\") {\n            let partialArguments: any = {};\n            try {\n              partialArguments = JSON.parse(untruncateJson(value.arguments));\n            } catch (e) {}\n\n            currentMessage.partialFunctionCall = {\n              name: value.name,\n              arguments: partialArguments,\n            };\n          }\n\n          newMessages[newMessages.length - 1] = currentMessage;\n          setMessages([...messages, ...newMessages]);\n\n          if (value.type === \"function\") {\n            // Execute the function call\n            try {\n              if (options.onFunctionCall && value.scope === \"client\") {\n                const result = await options.onFunctionCall(\n                  messages,\n                  currentMessage.function_call as FunctionCall,\n                );\n\n                currentMessage = {\n                  id: nanoid(),\n                  role: \"function\",\n                  content: encodeResult(result),\n                  name: (currentMessage.function_call! as FunctionCall).name!,\n                };\n                newMessages.push(currentMessage);\n                setMessages([...messages, ...newMessages]);\n\n                // After a function call, feed back the new messages to GPT\n                feedback = true;\n              }\n            } catch (error) {\n              console.error(\"Failed to execute function call\", error);\n              // TODO: Handle error\n              // this should go to the message itself\n            }\n          }\n        }\n      }\n\n      // If we want feedback, run the completion again and return the results\n      if (feedback) {\n        return await runChatCompletion([...messages, ...newMessages]);\n      }\n      // otherwise, return the new messages\n      else {\n        return newMessages.slice();\n      }\n    } finally {\n      setIsLoading(false);\n    }\n  };\n\n  const runChatCompletionAndHandleFunctionCall = async (messages: Message[]): Promise<void> => {\n    await runChatCompletion(messages);\n  };\n\n  const append = async (message: Message): Promise<void> => {\n    if (isLoading) {\n      return;\n    }\n    const newMessages = [...messages, message];\n    setMessages(newMessages);\n    return runChatCompletionAndHandleFunctionCall(newMessages);\n  };\n\n  const reload = async (): Promise<void> => {\n    if (isLoading || messages.length === 0) {\n      return;\n    }\n    let newMessages = [...messages];\n    const lastMessage = messages[messages.length - 1];\n\n    if (lastMessage.role === \"assistant\") {\n      newMessages = newMessages.slice(0, -1);\n    }\n    setMessages(newMessages);\n\n    return runChatCompletionAndHandleFunctionCall(newMessages);\n  };\n\n  const stop = (): void => {\n    abortControllerRef.current?.abort();\n  };\n\n  return {\n    append,\n    reload,\n    stop,\n    isLoading,\n    input,\n    setInput,\n  };\n}\n","import {\n  Message,\n  ToolDefinition,\n  ChatCompletionEvent,\n  decodeChatCompletion,\n  parseChatCompletion,\n  decodeChatCompletionAsText,\n  EXCLUDE_FROM_FORWARD_PROPS_KEYS,\n} from \"@copilotkit/shared\";\nimport { CopilotApiConfig } from \"../context\";\n\nexport interface FetchChatCompletionParams {\n  copilotConfig: CopilotApiConfig;\n  model?: string;\n  messages: Message[];\n  tools?: ToolDefinition[];\n  temperature?: number;\n  maxTokens?: number;\n  headers?: Record<string, string> | Headers;\n  body?: object;\n  signal?: AbortSignal;\n}\n\nexport async function fetchChatCompletion({\n  copilotConfig,\n  model,\n  messages,\n  tools,\n  temperature,\n  headers,\n  body,\n  signal,\n}: FetchChatCompletionParams): Promise<Response> {\n  temperature ||= 0.5;\n  tools ||= [];\n\n  // clean up any extra properties from messages\n  const cleanedMessages = messages.map((message) => {\n    const { content, role, name, function_call } = message;\n    return { content, role, name, function_call };\n  });\n\n  const response = await fetch(copilotConfig.chatApiEndpoint, {\n    method: \"POST\",\n    headers: {\n      \"Content-Type\": \"application/json\",\n      ...copilotConfig.headers,\n      ...(headers ? { ...headers } : {}),\n    },\n    body: JSON.stringify({\n      model,\n      messages: cleanedMessages,\n      stream: true,\n      ...(tools.length ? { tools } : {}),\n      ...(temperature ? { temperature } : {}),\n      ...(tools.length != 0 ? { tool_choice: \"auto\" } : {}),\n      ...copilotConfig.body,\n      ...copilotConfig.backendOnlyProps,\n      ...excludeBackendOnlyProps(copilotConfig),\n      ...(body ? { ...body } : {}),\n      ...(copilotConfig.cloud ? { cloud: copilotConfig.cloud } : {}),\n    }),\n    signal,\n  });\n\n  return response;\n}\n\nfunction excludeBackendOnlyProps(copilotConfig: any) {\n  const backendOnlyProps = copilotConfig.backendOnlyProps ?? {};\n  if (Object.keys(backendOnlyProps).length > 0) {\n    return {\n      [EXCLUDE_FROM_FORWARD_PROPS_KEYS]: Object.keys(backendOnlyProps),\n    };\n  } else {\n    return {};\n  }\n}\n\nexport interface DecodedChatCompletionResponse extends Response {\n  events: ReadableStream<ChatCompletionEvent> | null;\n}\n\nexport async function fetchAndDecodeChatCompletion(\n  params: FetchChatCompletionParams,\n): Promise<DecodedChatCompletionResponse> {\n  const response = await fetchChatCompletion(params);\n  if (!response.ok || !response.body) {\n    (response as any).events = null;\n  } else {\n    const events = await decodeChatCompletion(parseChatCompletion(response.body));\n    (response as any).events = events;\n  }\n  return response as any;\n}\n\nexport interface DecodedChatCompletionResponseAsText extends Response {\n  events: ReadableStream<string> | null;\n}\n\nexport async function fetchAndDecodeChatCompletionAsText(\n  params: FetchChatCompletionParams,\n): Promise<DecodedChatCompletionResponseAsText> {\n  const response = await fetchChatCompletion(params);\n  if (!response.ok || !response.body) {\n    (response as any).events = null;\n  } else {\n    const events = await decodeChatCompletionAsText(\n      decodeChatCompletion(parseChatCompletion(response.body)),\n    );\n    (response as any).events = events;\n  }\n\n  return response as any;\n}\n"],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,mBAAiC;AACjC,IAAAA,iBAOO;AAEP,oBAAuB;;;ACVvB,oBAQO;AAeP,SAAsB,oBAAoB,IASO;AAAA,6CATP;AAAA,IACxC;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EACF,GAAiD;AAC/C,kCAAgB;AAChB,sBAAU,CAAC;AAGX,UAAM,kBAAkB,SAAS,IAAI,CAAC,YAAY;AAChD,YAAM,EAAE,SAAS,MAAM,MAAM,cAAc,IAAI;AAC/C,aAAO,EAAE,SAAS,MAAM,MAAM,cAAc;AAAA,IAC9C,CAAC;AAED,UAAM,WAAW,MAAM,MAAM,cAAc,iBAAiB;AAAA,MAC1D,QAAQ;AAAA,MACR,SAAS;AAAA,QACP,gBAAgB;AAAA,SACb,cAAc,UACb,UAAU,mBAAK,WAAY,CAAC;AAAA,MAElC,MAAM,KAAK,UAAU;AAAA,QACnB;AAAA,QACA,UAAU;AAAA,QACV,QAAQ;AAAA,SACJ,MAAM,SAAS,EAAE,MAAM,IAAI,CAAC,IAC5B,cAAc,EAAE,YAAY,IAAI,CAAC,IACjC,MAAM,UAAU,IAAI,EAAE,aAAa,OAAO,IAAI,CAAC,IAChD,cAAc,OACd,cAAc,mBACd,wBAAwB,aAAa,IACpC,OAAO,mBAAK,QAAS,CAAC,IACtB,cAAc,QAAQ,EAAE,OAAO,cAAc,MAAM,IAAI,CAAC,EAC7D;AAAA,MACD;AAAA,IACF,CAAC;AAED,WAAO;AAAA,EACT;AAAA;AAEA,SAAS,wBAAwB,eAAoB;AApErD;AAqEE,QAAM,oBAAmB,mBAAc,qBAAd,YAAkC,CAAC;AAC5D,MAAI,OAAO,KAAK,gBAAgB,EAAE,SAAS,GAAG;AAC5C,WAAO;AAAA,MACL,CAAC,6CAA+B,GAAG,OAAO,KAAK,gBAAgB;AAAA,IACjE;AAAA,EACF,OAAO;AACL,WAAO,CAAC;AAAA,EACV;AACF;AAMA,SAAsB,6BACpB,QACwC;AAAA;AACxC,UAAM,WAAW,MAAM,oBAAoB,MAAM;AACjD,QAAI,CAAC,SAAS,MAAM,CAAC,SAAS,MAAM;AAClC,MAAC,SAAiB,SAAS;AAAA,IAC7B,OAAO;AACL,YAAM,SAAS,UAAM,wCAAqB,mCAAoB,SAAS,IAAI,CAAC;AAC5E,MAAC,SAAiB,SAAS;AAAA,IAC7B;AACA,WAAO;AAAA,EACT;AAAA;;;ADjFA,6BAA2B;AAoFpB,SAAS,QAAQ,SAA0D;AAChF,QAAM,EAAE,UAAU,YAAY,IAAI;AAClC,QAAM,CAAC,OAAO,QAAQ,QAAI,uBAAS,EAAE;AACrC,QAAM,CAAC,WAAW,YAAY,QAAI,uBAAS,KAAK;AAChD,QAAM,yBAAqB,qBAAwB;AACnD,QAAM,kBAAc,qBAAsB,IAAI;AAC9C,QAAM,eAAW,qBAAsB,IAAI;AAC3C,QAAM,eAAe,QAAQ,cAAc;AAC3C,QAAM,UAAU,kCACV,QAAQ,WAAW,CAAC,IACpB,eAAe,EAAE,CAAC,kDAAmC,GAAG,aAAa,IAAI,CAAC;AAGhF,QAAM,oBAAoB,CAAOC,cAA4C;AAC3E,iBAAa,IAAI;AAEjB,UAAM,cAAyB;AAAA,MAC7B;AAAA,QACE,QAAI,sBAAO;AAAA,QACX,WAAW,oBAAI,KAAK;AAAA,QACpB,SAAS;AAAA,QACT,MAAM;AAAA,MACR;AAAA,IACF;AACA,UAAM,kBAAkB,IAAI,gBAAgB;AAC5C,uBAAmB,UAAU;AAE7B,gBAAY,CAAC,GAAGA,WAAU,GAAG,WAAW,CAAC;AAGzC,UAAM,oBAAoB,QAAQ,cAAc,QAAQ,CAAC;AACzD,QAAI,YAAY,SAAS;AACvB,wBAAkB,WAAW,YAAY;AAAA,IAC3C;AACA,QAAI,SAAS,SAAS;AACpB,wBAAkB,QAAQ,SAAS;AAAA,IACrC;AAEA,UAAM,sBAAsB,CAAC,GAAI,QAAQ,mBAAmB,CAAC,GAAI,GAAGA,SAAQ;AAC5E,UAAM,WAAW,MAAM,6BAA6B;AAAA,MAClD,eAAe,iCAAK,QAAQ,gBAAb,EAA4B,MAAM,kBAAkB;AAAA,MACnE,UAAU;AAAA,MACV,OAAO,QAAQ;AAAA,MACf;AAAA,MACA,QAAQ,gBAAgB;AAAA,IAC1B,CAAC;AAED,QAAI,SAAS,QAAQ,IAAI,UAAU,GAAG;AACpC,kBAAY,UAAU,SAAS,QAAQ,IAAI,UAAU;AAAA,IACvD;AAEA,QAAI,SAAS,QAAQ,IAAI,OAAO,GAAG;AACjC,eAAS,UAAU,SAAS,QAAQ,IAAI,OAAO;AAAA,IACjD;AAEA,QAAI,CAAC,SAAS,QAAQ;AACpB,kBAAY;AAAA,QACV,GAAGA;AAAA,QACH;AAAA,UACE,QAAI,sBAAO;AAAA,UACX,WAAW,oBAAI,KAAK;AAAA,UACpB,SAAS,SAAS;AAAA,UAClB,MAAM;AAAA,QACR;AAAA,MACF,CAAC;AACD,mBAAa,KAAK;AAClB,YAAM,IAAI,MAAM,iCAAiC;AAAA,IACnD;AAEA,UAAM,SAAS,SAAS,OAAO,UAAU;AAGzC,QAAI,WAAW;AAEf,QAAI;AACF,aAAO,MAAM;AACX,cAAM,EAAE,MAAM,MAAM,IAAI,MAAM,OAAO,KAAK;AAE1C,YAAI,MAAM;AACR;AAAA,QACF;AAEA,YAAI,iBAAiB,OAAO,OAAO,CAAC,GAAG,YAAY,YAAY,SAAS,CAAC,CAAC;AAE1E,YAAI,MAAM,SAAS,WAAW;AAC5B,cAAI,eAAe,iBAAiB,eAAe,SAAS,YAAY;AAEtE,6BAAiB;AAAA,cACf,QAAI,sBAAO;AAAA,cACX,WAAW,oBAAI,KAAK;AAAA,cACpB,SAAS;AAAA,cACT,MAAM;AAAA,YACR;AACA,wBAAY,KAAK,cAAc;AAAA,UACjC;AACA,yBAAe,WAAW,MAAM;AAChC,sBAAY,YAAY,SAAS,CAAC,IAAI;AACtC,sBAAY,CAAC,GAAGA,WAAU,GAAG,WAAW,CAAC;AAAA,QAC3C,WAAW,MAAM,SAAS,UAAU;AAElC,2BAAiB;AAAA,YACf,QAAI,sBAAO;AAAA,YACX,MAAM;AAAA,YACN,SAAS,MAAM;AAAA,YACf,MAAM,MAAM;AAAA,UACd;AACA,sBAAY,KAAK,cAAc;AAC/B,sBAAY,CAAC,GAAGA,WAAU,GAAG,WAAW,CAAC;AAGzC,qBAAW;AAAA,QACb,WAAW,MAAM,SAAS,cAAc,MAAM,SAAS,WAAW;AAEhE,cACE,eAAe,WAAW,MAC1B,eAAe,iBACf,eAAe,QAAQ,YACvB;AACA,6BAAiB;AAAA,cACf,QAAI,sBAAO;AAAA,cACX,WAAW,oBAAI,KAAK;AAAA,cACpB,SAAS;AAAA,cACT,MAAM;AAAA,YACR;AACA,wBAAY,KAAK,cAAc;AAAA,UACjC;AACA,cAAI,MAAM,SAAS,YAAY;AAC7B,2BAAe,gBAAgB;AAAA,cAC7B,MAAM,MAAM;AAAA,cACZ,WAAW,KAAK,UAAU,MAAM,SAAS;AAAA,cACzC,OAAO,MAAM;AAAA,YACf;AAAA,UACF,WAAW,MAAM,SAAS,WAAW;AACnC,gBAAI,mBAAwB,CAAC;AAC7B,gBAAI;AACF,iCAAmB,KAAK,UAAM,uBAAAC,SAAe,MAAM,SAAS,CAAC;AAAA,YAC/D,SAAS,GAAP;AAAA,YAAW;AAEb,2BAAe,sBAAsB;AAAA,cACnC,MAAM,MAAM;AAAA,cACZ,WAAW;AAAA,YACb;AAAA,UACF;AAEA,sBAAY,YAAY,SAAS,CAAC,IAAI;AACtC,sBAAY,CAAC,GAAGD,WAAU,GAAG,WAAW,CAAC;AAEzC,cAAI,MAAM,SAAS,YAAY;AAE7B,gBAAI;AACF,kBAAI,QAAQ,kBAAkB,MAAM,UAAU,UAAU;AACtD,sBAAM,SAAS,MAAM,QAAQ;AAAA,kBAC3BA;AAAA,kBACA,eAAe;AAAA,gBACjB;AAEA,iCAAiB;AAAA,kBACf,QAAI,sBAAO;AAAA,kBACX,MAAM;AAAA,kBACN,aAAS,6BAAa,MAAM;AAAA,kBAC5B,MAAO,eAAe,cAAgC;AAAA,gBACxD;AACA,4BAAY,KAAK,cAAc;AAC/B,4BAAY,CAAC,GAAGA,WAAU,GAAG,WAAW,CAAC;AAGzC,2BAAW;AAAA,cACb;AAAA,YACF,SAAS,OAAP;AACA,sBAAQ,MAAM,mCAAmC,KAAK;AAAA,YAGxD;AAAA,UACF;AAAA,QACF;AAAA,MACF;AAGA,UAAI,UAAU;AACZ,eAAO,MAAM,kBAAkB,CAAC,GAAGA,WAAU,GAAG,WAAW,CAAC;AAAA,MAC9D,OAEK;AACH,eAAO,YAAY,MAAM;AAAA,MAC3B;AAAA,IACF,UAAE;AACA,mBAAa,KAAK;AAAA,IACpB;AAAA,EACF;AAEA,QAAM,yCAAyC,CAAOA,cAAuC;AAC3F,UAAM,kBAAkBA,SAAQ;AAAA,EAClC;AAEA,QAAM,SAAS,CAAO,YAAoC;AACxD,QAAI,WAAW;AACb;AAAA,IACF;AACA,UAAM,cAAc,CAAC,GAAG,UAAU,OAAO;AACzC,gBAAY,WAAW;AACvB,WAAO,uCAAuC,WAAW;AAAA,EAC3D;AAEA,QAAM,SAAS,MAA2B;AACxC,QAAI,aAAa,SAAS,WAAW,GAAG;AACtC;AAAA,IACF;AACA,QAAI,cAAc,CAAC,GAAG,QAAQ;AAC9B,UAAM,cAAc,SAAS,SAAS,SAAS,CAAC;AAEhD,QAAI,YAAY,SAAS,aAAa;AACpC,oBAAc,YAAY,MAAM,GAAG,EAAE;AAAA,IACvC;AACA,gBAAY,WAAW;AAEvB,WAAO,uCAAuC,WAAW;AAAA,EAC3D;AAEA,QAAM,OAAO,MAAY;AA3T3B;AA4TI,6BAAmB,YAAnB,mBAA4B;AAAA,EAC9B;AAEA,SAAO;AAAA,IACL;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EACF;AACF;","names":["import_shared","messages","untruncateJson"]}